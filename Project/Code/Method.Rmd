---
title: "Method"
author: "Yue Zhang"
date: "2025-07-29"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
#This code chunk will tidy your knit PDF files, wrapping long code lines
#For it to work, the "formatR" package needs to be installed
#install.packages('formatR')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)

```

#OVERVIEW

This R Markdown file aims for GAM and GWR


#Set Working Directory and Load Packages
```{r packages, message = FALSE, warning = FALSE}
setwd("/Users/yuezhang/Documents/Biostat/Biostatistics/Project")
getwd()
library(data.table)
library(dplyr)
library(terra)
library(sf)
library(stringr)
library(tidyverse)
library(purrr)
library(ggplot2)
library(ggspatial)
library(RColorBrewer)
library(viridis)
library(scales)
library(daymetr)
library(ncdf4)
library(cmocean)
library(magick)
library(spdep)
library(tmap)
library(ragg)
library(mgcv)
library(spgwr)
library(GWmodel)
library(leaflet)
library(car)
library(ggcorrplot)
library(gratia)

```

#Load data
```{r load data, message = FALSE, warning = FALSE}
wind = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/wind_bg.csv")
pm25 = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/pm25_bg.csv")
ozone = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/o3_bg.csv")
bc = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/bc_bg.csv")
temp = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/temp_bg.csv")
ndvi = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/ndvi_bg.csv")
demo = fread("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/LA_demo(2000-2020).csv")
road = st_read("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Raw/tl_2010_06037_roads/tl_2010_06037_roads.shp")
la_bg_2010 = st_read("/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Raw/tl_2010_06037_bg10/")
la_boundary = st_read(
  "/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Raw/City_Boundary/City_Boundary.shp"
)

```

#EDA
```{r eda, warning = FALSE, message = FALSE}
#Convert env variables wide to long
melt_env = function(dt, var_prefix, id = "GEOID10") {
  long = melt(dt, id.vars = id, variable.name = "year", value.name = var_prefix)
  # Extract year as numeric
  long[, year := as.integer(gsub(".*_", "", year))]
  setnames(long, id, "GEOID")
  return(long[, .(GEOID, year, get(var_prefix))])
}

ozone_long = melt_env(ozone, "O3")
pm25_long = melt_env(pm25, "PM25")
bc_long = melt_env(bc, "BC")
ndvi_long = melt_env(ndvi, "NDVI")
wind_long = melt_env(wind, "Wind")
temp_long = melt_env(temp, "Temp")

ozone_long$GEOID = sprintf("%012s", as.character(ozone_long$GEOID))
ndvi_long$GEOID = sprintf("%012s", as.character(ndvi_long$GEOID))
pm25_long$GEOID = sprintf("%012s", as.character(pm25_long$GEOID))
bc_long$GEOID = sprintf("%012s", as.character(bc_long$GEOID))
temp_long$GEOID = sprintf("%012s", as.character(temp_long$GEOID))
wind_long$GEOID = sprintf("%012s", as.character(wind_long$GEOID))
demo$GEOID = sprintf("%012s", as.character(demo$GEOID))
setnames(ozone_long, "V3", "O3")
setnames(ndvi_long, "V3", "NDVI")
setnames(pm25_long, "V3", "PM25")
setnames(bc_long, "V3", "BC")
setnames(temp_long, "V3", "Temp")
setnames(wind_long, "V3", "Wind")

#Merge all variables
setkey(ozone_long, GEOID, year)
setkey(pm25_long, GEOID, year)
setkey(bc_long, GEOID, year)
setkey(ndvi_long, GEOID, year)
setkey(wind_long, GEOID, year)
setkey(temp_long, GEOID, year)
setkey(demo, GEOID, year)

data_long = Reduce(
  function(x, y)
    merge(x, y, by = c("GEOID", "year"), all = TRUE),
  list(ozone_long, pm25_long, bc_long, ndvi_long, wind_long, temp_long, demo)
)

write.csv(data_long, "data_bg_year.csv", row.names = FALSE)

```

#Add traffic category
```{r traffic, message = FALSE, warning = FALSE}
#Set crs as EPSG:2229 to set buffer in feet
road_2229 = st_transform(road, 2229)
la_bg_2010_2229 = st_transform(la_bg_2010, 2229)
la_boundary_2229 = st_transform(la_boundary, 2229)

road_wgs84 = st_transform(road, 4326)
la_bg_2010_wgs84 = st_transform(la_bg_2010, 4326)
la_boundary_wgs84 = st_transform(la_boundary, 4326)

#Intersect block group to LA
la_bg_2010_2229 = st_intersection(la_bg_2010_2229, la_boundary_2229)

#Clip roads to LA
road_la = st_intersection(road_2229, la_boundary_2229)

#Filter major roads
road_major = road_la %>% filter(MTFCC %in% c("S1100", "S1200"))

#Set buffers
buffer_500 = st_buffer(road_major, 500)
buffer_1000 = st_buffer(road_major, 1000)

road_major_wgs84 = st_transform(road_major, 4326)
buffer500_wgs84 = st_transform(buffer_500, 4326)
buffer1000_wgs84 = st_transform(buffer_1000, 4326)

leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = la_bg_2010_wgs84, color = "#9a9a9a", weight = 1, fill = FALSE) %>%
  addPolylines(data = road_major_wgs84, color = "red", weight = 2) %>%
  addPolygons(data = la_boundary_wgs84, color = "black", weight = 2, fill = FALSE) %>% 
  addPolygons(data = buffer1000_wgs84, color = "lightblue", fill = TRUE) %>% 
  addPolygons(data = buffer500_wgs84, color = "lightyellow", fill = TRUE)


#Assign category per block group
bg_cent = st_centroid(la_bg_2010_2229)
bg_traffic = bg_cent %>% 
  mutate(traffic = case_when(
  lengths(st_intersects(geometry, buffer_500)) > 0 ~ "High",
  lengths(st_intersects(geometry, buffer_1000)) > 0 ~ "Medium",
  TRUE ~ "Low"
)) %>% 
  st_drop_geometry() %>% 
  select(GEOID10, traffic)

bg_traffic = bg_traffic %>% rename(GEOID = GEOID10)

```

#Obtain the final data table
```{r final data table, message = FALSE, warning = FALSE}
data_long = data_long %>% left_join(bg_traffic, by = "GEOID")

str(data_long)

#Add coordinates
la_bg_coord = la_bg_2010_wgs84 %>% 
  select(GEOID10, INTPTLAT10, INTPTLON10) %>% 
  st_drop_geometry() %>% rename(GEOID = GEOID10)

data_long = data_long %>% left_join(la_bg_coord, by = "GEOID") %>%
  mutate(
    traffic = factor(traffic, levels = c("Low", "Medium", "High")),
    lat = as.numeric(INTPTLAT10),
    lon = as.numeric(INTPTLON10),
    GEOID = factor(GEOID)
  ) %>%
  drop_na()


write.csv(data_long, "/Users/yuezhang/Documents/Biostat/Biostatistics/Project/Data/Processed/final_data.csv")
```

#Check collinearity
```{r collinearity, message = FALSE, warning = FALSE}
#VIF
pm25_lm = lm(
  data = data_long,
  PM25 ~ NDVI + Wind + Temp + nonwhite_pct + less_hs_pct + unemployment_pct + poverty_pct + pop_dens + traffic
)

o3_lm = lm(
  data = data_long,
  O3 ~ NDVI + Wind + Temp + nonwhite_pct + less_hs_pct + unemployment_pct + poverty_pct + pop_dens + traffic
)

bc_lm = lm(
  data = data_long,
  BC ~ NDVI + Wind + Temp + nonwhite_pct + less_hs_pct + unemployment_pct + poverty_pct + pop_dens + traffic
)

vif(pm25_lm)
vif(o3_lm)
vif(bc_lm)

#Correlation matrix
cont_vars = data_long %>%
  select(NDVI, Wind, Temp, nonwhite_pct, less_hs_pct,
         unemployment_pct, poverty_pct, pop_dens)

cor_mat = cor(cont_vars, use = "pairwise.complete.obs")

ggcorrplot(
  cor_mat,
  method = "square",
  type = "lower",           
  hc.order = TRUE,          
  lab = TRUE,               
  lab_size = 3,
  colors = c("#2166ac", "white", "#b2182b"), 
  hc.method = "complete",
  tl.srt = 45,              
  show.diag = NULL         
) +
  ggplot2::labs(title = "Covariate Correlations") +
  ggplot2::theme_minimal(base_size = 12) +
  ggplot2::theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)
  ) + 
  guides(fill = guide_colorbar(barheight = unit(10, "cm")))

```

#PCA based SES index
```{r PCA, message = FALSE, warning = FALSE}
SES = data_long[, c("nonwhite_pct", "less_hs_pct", "unemployment_pct", "poverty_pct")]
SES_pct = prcomp(SES, scale. = TRUE)
summary(SES_pct)
print(SES_pct$rotation)
data_long$SES_index = SES_pct$x[, 1]


```


#GAM
```{r GAM, message = FALSE, warning = FALSE}
#GAM for PM2.5
#pm_gam = bam(
  #data = data_long,
  #PM25 ~ s(NDVI) + s(Wind) + s(Temp) + s(SES_index) + s(pop_dens) + traffic + te(lat, lon),
  #method = "REML"
#)

pm_gam = bam(
  data = data_long,
  PM25 ~ s(NDVI, bs = "cs") + s(Wind, k = 30, bs = "cs") + s(Temp, k = 40, bs = "cs") +
    s(nonwhite_pct, k = 20, bs = "cs") + s(less_hs_pct, bs = "cs") + s(unemployment_pct, bs = "cs") +
    s(poverty_pct, k = 20, bs = "cs") + s(pop_dens, bs = "cs") +
    traffic + s(lat, lon, k = 170, bs = "gp", m = 2) + s(year, k = 20),
  method = "fREML",
  discrete = TRUE
)

summary(pm_gam)

concurvity(pm_gam, full = TRUE)

gam.check(pm_gam)

#plot(pm_gam, select = 1, shade = TRUE, main = "Effect of NDVI on PM2.5")

appraise(pm_gam, method = "simulate")
draw(pm_gam)


pm_gam_log = gam(
  log(PM25) ~ s(NDVI) + s(Temp) + s(Wind) + s(MHI) + s(nonwhite_per) + s(unemployed_per) + s(less_hs_per) + s(popdens_km2),
  data = df
)
summary(pm_gam_log)
plot(pm_gam_log, select = 1, shade = TRUE, main = "Effect of NDVI on PM2.5")

# Create new data for prediction
ndvi_vals = data.frame(
  NDVI = c(0.5, 0.6),
  Temp = mean(df$Temp, na.rm = TRUE),
  Wind = mean(df$Wind, na.rm = TRUE),
  MHI = mean(df$MHI, na.rm = TRUE),
  nonwhite_per = mean(df$nonwhite_per, na.rm = TRUE),
  unemployed_per = mean(df$unemployed_per, na.rm = TRUE),
  less_hs_per = mean(df$less_hs_per, na.rm = TRUE),
  popdens_km2 = mean(df$popdens_km2, na.rm = TRUE)
)

predicted_log_pm = predict(pm_gam_log, newdata = ndvi_vals)

# Convert log(PM2.5) back to PM2.5
predicted_pm = exp(predicted_log_pm)

# % difference
perc_change = (predicted_pm[1] - predicted_pm[2]) / predicted_pm[1] * 100
perc_change

ndvi_seq = seq(min(df$NDVI, na.rm = TRUE), max(df$NDVI, na.rm = TRUE), by = 0.01)

# Create newdata for prediction at each NDVI level, holding other covariates constant
newdata = data.frame(
  NDVI = ndvi_seq,
  Temp = median(df$Temp, na.rm = TRUE),
  Wind = median(df$Wind, na.rm = TRUE),
  MHI = median(as.numeric(df$MHI), na.rm = TRUE),
  nonwhite_per = median(df$nonwhite_per, na.rm = TRUE),
  unemployed_per = median(df$unemployed_per, na.rm = TRUE),
  less_hs_per = median(df$less_hs_per, na.rm = TRUE),
  popdens_km2 = median(df$popdens_km2, na.rm = TRUE)
)

# Predict PM2.5 at each NDVI value
pm_pred = predict(pm_gam, newdata = newdata, type = "response")

# Total reduction = PM2.5 at min NDVI - PM2.5 at max NDVI
pm25_start = pm_pred[1]
pm25_end = pm_pred[length(pm_pred)]
total_reduction = pm25_start - pm25_end
percent_reduction = (total_reduction / pm25_start) * 100

# Print results
cat("Estimated PM2.5 at NDVI =", round(ndvi_seq[1], 2), ":", round(pm25_start, 2), "µg/m³\n")
cat("Estimated PM2.5 at NDVI =", round(ndvi_seq[length(ndvi_seq)], 2), ":", round(pm25_end, 2), "µg/m³\n")
cat("Total reduction:", round(total_reduction, 2), "µg/m³ (", round(percent_reduction, 1), "%)\n")

#O3
o3_gam = gam(
  data = data_long,
  O3 ~ s(NDVI) + s(Wind) + s(Temp) + s(SES_index) + s(pop_dens) + traffic + te(lat, lon, k = c(30, 30)),
  method = "REML"
)
summary(o3_gam)
plot(o3_gam, select = 1, shade = TRUE, main = "Effect of NDVI on O3")

o3_gam_log = gam(
  log(O3) ~ s(NDVI) + s(Temp) + s(Wind) + s(MHI) + s(nonwhite_per) + s(unemployed_per) + s(less_hs_per) + s(popdens_km2),
  data = df
)
summary(o3_gam_log)
plot(o3_gam_log, select = 1, shade = TRUE, main = "Effect of NDVI on O3")

# Create new data for prediction
ndvi_vals_o3 = data.frame(
  NDVI = c(0.6, 0.7),
  Temp = mean(df$Temp, na.rm = TRUE),
  Wind = mean(df$Wind, na.rm = TRUE),
  MHI = mean(df$MHI, na.rm = TRUE),
  nonwhite_per = mean(df$nonwhite_per, na.rm = TRUE),
  unemployed_per = mean(df$unemployed_per, na.rm = TRUE),
  less_hs_per = mean(df$less_hs_per, na.rm = TRUE),
  popdens_km2 = mean(df$popdens_km2, na.rm = TRUE)
)

predicted_log_o3 = predict(o3_gam_log, newdata = ndvi_vals_o3)

# Convert log(O3) back to O3
predicted_o3 = exp(predicted_log_o3)

# % difference
perc_change_o3 = (predicted_o3[1] - predicted_o3[2]) / predicted_o3[1] * 100
perc_change_o3



# Predict O3 at each NDVI value
o3_pred = predict(o3_gam, newdata = newdata, type = "response")

# Total reduction = O3 at min NDVI - O3 at max NDVI
o3_start = o3_pred[1]
o3_end = o3_pred[length(o3_pred)]
total_reduction_o3 = o3_start - o3_end
percent_reduction_o3 = (total_reduction_o3 / o3_start) * 100

# Print results
cat("Estimated O3 at NDVI =", round(ndvi_seq[1], 2), ":", round(o3_start, 2), "ppb")
cat("Estimated O3 at NDVI =", round(ndvi_seq[length(ndvi_seq)], 2), ":", round(o3_end, 2), "ppb")
cat("Total reduction:", round(total_reduction_o3, 2), "ppb (", round(percent_reduction_o3, 1), "%)\n")

#BC
bc_gam = gam(
  data = data_long,
  BC ~ s(NDVI) + s(Wind) + s(Temp) + s(SES_index) + s(pop_dens) + traffic + te(lat, lon, k = c(30, 30)),
  method = "REML"
)
summary(bc_gam)
plot(bc_gam, select = 1, shade = TRUE, main = "Effect of NDVI on BC")

bc_gam_log = gam(
  log(BC) ~ s(NDVI) + s(Temp) + s(Wind) + s(MHI) + s(nonwhite_per) + s(unemployed_per) + s(less_hs_per) + s(popdens_km2),
  data = df
)
summary(bc_gam_log)
plot(bc_gam_log, select = 1, shade = TRUE, main = "Effect of NDVI on BC")

# Create new data for prediction
ndvi_vals_bc = data.frame(
  NDVI = c(0.6, 0.7),
  Temp = mean(df$Temp, na.rm = TRUE),
  Wind = mean(df$Wind, na.rm = TRUE),
  MHI = mean(df$MHI, na.rm = TRUE),
  nonwhite_per = mean(df$nonwhite_per, na.rm = TRUE),
  unemployed_per = mean(df$unemployed_per, na.rm = TRUE),
  less_hs_per = mean(df$less_hs_per, na.rm = TRUE),
  popdens_km2 = mean(df$popdens_km2, na.rm = TRUE)
)

predicted_log_bc = predict(bc_gam_log, newdata = ndvi_vals_bc)

# Convert log(BC) back to BC
predicted_bc = exp(predicted_log_bc)

# % difference
perc_change_bc = (predicted_bc[1] - predicted_bc[2]) / predicted_bc[1] * 100
perc_change_bc

# Predict BC at each NDVI value
bc_pred = predict(bc_gam, newdata = newdata, type = "response")

# Total reduction = BC at min NDVI - BC at max NDVI
bc_start = bc_pred[1]
bc_end = bc_pred[length(bc_pred)]
total_reduction_bc = bc_start - bc_end
percent_reduction_bc = (total_reduction_bc / bc_start) * 100

# Print results
cat("Estimated BC at NDVI =", round(ndvi_seq[1], 2), ":", round(bc_start, 2), "µg/m³\n")
cat("Estimated BC at NDVI =", round(ndvi_seq[length(ndvi_seq)], 2), ":", round(bc_end, 2), "µg/m³\n")
cat("Total reduction:", round(total_reduction_bc, 2), "µg/m³ (", round(percent_reduction_bc, 1), "%)\n")

```


#GWR
```{r gwr, warning = FALSE, message = FALSE}
years = sort(unique(df$year))
gwr_results_list = list()

for (yr in years) {
  cat("Processing year:", yr, "\n")
  
  # 1. Subset data for year
  df_year = df %>% filter(year == yr)
  
  # 2. Match polygons (keep only those in df_year, in same order)
  la_bg_year = la_bg %>% filter(GEOID10 %in% df_year$GEOID)
  
  # 3. Order both by GEOID to align rows!
  la_bg_year = la_bg_year[order(la_bg_year$GEOID10), ]
  df_year = df_year[order(df_year$GEOID), ]
  
  # 4. Check
  stopifnot(nrow(la_bg_year) == nrow(df_year))
  stopifnot(all(la_bg_year$GEOID10 == df_year$GEOID))
  
  # 5. Get centroids
  coords = st_coordinates(st_centroid(la_bg_year))
  
  # 6. GWR bandwidth selection
  gwr_bw <- gwr.sel(
    PM25 ~ NDVI + Temp + Wind + MHI + nonwhite_per + unemployed_per + less_hs_per + popdens_km2,
    data = df_year,
    coords = coords,
    adapt = TRUE
  )
  
  # 7. Run GWR
  gwr_mod_pm = gwr(
    PM25 ~ NDVI + Temp + Wind + MHI + nonwhite_per + unemployed_per + less_hs_per + popdens_km2,
    data = df_year,
    coords = coords,
    adapt = gwr_bw,
    hatmatrix = TRUE
  )
  
  # 8. Store results (local NDVI coefficients, etc.)
  df_gwr$gwr_ndvi_coef = gwr_mod_pm$SDF$NDVI
  df_gwr$year = yr
  gwr_results_list[[as.character(yr)]] = df_gwr
  
  cat("Year", yr, "completed.\n")
}



```

